#Arguments needed by main.py
scenario: PredatorCapturePrey #name of the folder inside scenarios

model_config_file: qmix.json
model_file: qmix.th

actor_file: rnn_agent
actor_class: RNNAgent

env_file: PredatorCapturePrey
env_class: PredatorCapturePrey #This needs to have all of the functionalities of a gym to work
n_actions: 5 #The number of actions available for the agent
n_agents: 4
episodes: 10 #Number of episodes to run for
shared_reward: True
seed: -1 #sets the seed. Set to -1 to use a random seed.

#Arguments needed by the environment
#The follow four arguments are the boundaries in the Robotarium that the robots are allowed to traverse to
LEFT: -1.4
RIGHT: 1.4
UP: -0.9
DOWN: .9
ROBOT_INIT_RIGHT_THRESH : -0.5
PREY_INIT_LEFT_THRESH : 0.5
step_dist : 0.2 #This should probably be renamed. This is actually the amount of distance the robots move per time step...
start_dist: 0.3 #Minimum distance the agents start from each other
barrier_certificate: safe #Can be safe or default for strong or weak barrier certificates
time_penalty: -0.05
sense_reward: 1
capture_reward: 5
predator: 2
predator_radius: .45
capture: 2
capture_radius: .25
capability_aware: False #If true, the agents know their capture/sensing radius. Probably shouldn't use ids if true. Make sure this argument matches how the models were trained
penalize_violations: True #If true, agents get a negative reward for collisions or boundary infractions and the episode stops
show_figure_frequency: -1 #Set to -1 to turn off figures. Needs to be 1 when submitting to Robotarium
real_time: False
num_neighbors: 3
max_episode_steps: 80
update_frequency: 29
num_prey: 6
robotarium: False #Should be False during training to speed up robots, needs to be true when submitting
