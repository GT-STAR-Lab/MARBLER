#Arguments needed by main.py
scenario: PredatorCapturePrey #name of the folder inside scenarios

model_config_file: qmix_ns.json
model_file: qmix_ns.th

actor_file: rnn_ns_agent
actor_class: RNNNSAgent

env_file: pcpAgents
env_class: pcpAgents #This needs to have all of the functionalities of a gym to work
n_actions: 5 #The number of actions available for the agent
n_agents: 4
episodes: 10 #Number of episodes to run for
shared_reward: True

#Arguments needed by the environment
#The follow four arguments are the boundaries in the Robotarium that the robots are allowed to traverse to
LEFT: -1.35
RIGHT: 1.35
UP: -0.85
DOWN: .85
ROBOT_INIT_RIGHT_THRESH : -0.5
PREY_INIT_LEFT_THRESH : 0.5
MIN_DIST : 0.2 #This should probably be renamed. This is actually the amount of distance the robots move per time step...
START_DIST: 0.3 #Minimum distance the agents start from each other
time_penalty: -0.05
sense_reward: 1 
capture_reward: 5
predator: 2
predator_radius: .45
capture: 2
capture_radius: .225
show_figure_frequency: -1 #Set to -1 to turn off figures. Needs to be 1 when submitting to Robotarium
real_time: False
delta: 0.0 #If > 0, make sure that the agent can handle changing observation sizes
num_neighbors: 3
max_episode_steps: 80
update_frequency: 34
num_prey: 6
robotarium: False #Should be False during training to speed up robots, needs to be true when submitting
