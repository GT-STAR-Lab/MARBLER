#Arguments needed to create proper paths to everything
scenario: MaterialTransport #name of the folder inside scenarios
model_config_file: mappo.json #The config file from sacred for the model
model_file: mappo.th #The saved model weights
actor_file: rnn_agent #The file the actor model architecture lives in
actor_class: RNNAgent #The class the actor model architecture is in
env_file: MaterialTransport #The .py file this environment is in
env_class: MaterialTransport #This needs to have all of the functionalities of a gym to work

#Arguments needed by main, will not affect training
n_actions: 20 #The number of actions available for the agent
episodes: 10 #Number of episodes to run for
shared_reward: True #Purely for evaluation information

seed: -1 #sets the seed. Set to -1 to use a random seed.

#Arguments neeeded for most scenarios
n_agents: 4 #Number of agents to run
show_figure_frequency: -1 #Set to -1 to turn off figures. Needs to be 1 when submitting to Robotarium
real_time: False #Set to true for debugging only
max_episode_steps: 70 #maximum number of steps an episode can take
update_frequency: 74 #How often new actions are given to the robotarium
start_dist: .3 #Minimum distance the agents start from each other
robotarium: False #Should be False during training to speed up robots, needs to be true when submitting
barrier_certificate: safe #Can be safe or default for strong or weak barrier certificates
penalize_violations: True #If true, agents get a negative reward for collisions or boundary infractions and the episode stops
LEFT: -1.40 #Minimum x coordinate the robots are allowed to navigate to and start at
RIGHT: 1.40 #Maxiumum x coordinate the robots are allowed to navigate to and start at
UP: -0.9 #Minimum y coordinate the robots are allowed to navigate to and start at
DOWN: 0.9 #Maxiumum y coordinate the robots are allowed to navigate to and start at

#Arguments needed by this scenario
n_fast_agents: 2
n_slow_agents: 2
fast_step: .45
slow_step: .15
large_torque: 15
small_torque: 5
unload_multiplier: .075
load_multiplier: .025
end_goal_width: .5
time_penalty: -0.1
capability_aware: False #Whether or not the agents know their own capabilities. Should probably not use ids if this is true
zone1_radius: .35
zone1:
  distribution: 'normal'
  loc: 100
  scale: 10
zone2:
  distribution: 'normal'
  loc: 20
  scale: 4
